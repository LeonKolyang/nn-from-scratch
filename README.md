# Neural Networks from Scratch
This project is more of a personal documentation of my journey of playing around with neural networks and python.
It has been a few years since I went really deep into the fundamentals of neural networks, and I gained quite a lot of understanding and intuition about maths, statistics, and software engineering in the meantime. 

For the first milestone, I want to combine my knowledge and have some fun with python. I will explain the concepts and implementations alongside the code to produce lasting value. My younger brother just started studying AI, and he should be able to make sense of the code and maths happening here. The goal is to reach a modular neural network implementation that can be used to solve basic classification and regression tasks.

The second milestone will be to implement a transformer architecture from scratch, hopefully reusing as much as possible from the first part. Over the past few months, I helped many people make sense of text generation with language models and went deep on transformers and the integration into applications. The last missing piece in my understanding is the actual implementation of those models. By doing that, I hope to gain a better intuition about the costly parts of training and inference and techniques like quantization and pruning.

## How to use this repository
Each chapter has multiple python scripts and a README.md. The order of the scripts reflects the increase in complexity and features of the neural network. The README.md explains the mathematical intuition behind the code.

To follow along, simply open the README.md on the side and click through the links in the document. The links will bring you to the corresponding places in the code. 

## Chapters
- Chapter 1: [Basic Neural Network and Backpropagation](./basic_nn_and_backpropagation/README.md)